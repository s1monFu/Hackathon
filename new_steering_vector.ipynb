{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a71d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEERING_VECTOR_FILE_PATH = \"steering_vector_normalized_meandiff_normalized_nuisance_normalized_steering.pkl\"\n",
    "PROMPTS_FILE_PATH_FULL = \"vector_steering_samples_full.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a8525a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pprint\n",
    "import pickle\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from enhanced_hooking import (\n",
    "    get_activations,\n",
    "    add_activations_and_generate,\n",
    "    zeroout_projections_and_generate,\n",
    "    clear_hooks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48093b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:43<00:00, 10.79s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "model      = AutoModelForCausalLM.from_pretrained(\n",
    "                 model_name,\n",
    "                 torch_dtype=torch.float16,\n",
    "                 device_map=\"auto\")\n",
    "tok        = AutoTokenizer.from_pretrained(model_name)\n",
    "tok.pad_token = tok.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328de304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.defaultdict'>\n",
      "defaultdict(<class 'list'>,\n",
      "            {0: [tensor([ 0.0090, -0.0055,  0.0264,  ...,  0.0223,  0.0064,  0.0043]),\n",
      "                 tensor([ 0.0079,  0.0168,  0.0028,  ..., -0.0092,  0.0149,  0.0272]),\n",
      "                 tensor([-0.0108,  0.0001,  0.0082,  ..., -0.0129,  0.0061, -0.0278]),\n",
      "                 tensor([ 0.0119,  0.0115,  0.0173,  ..., -0.0148, -0.0070,  0.0079]),\n",
      "                 tensor([ 0.0037,  0.0228, -0.0113,  ...,  0.0059, -0.0114,  0.0269]),\n",
      "                 tensor([ 0.0040,  0.0133, -0.0027,  ...,  0.0268, -0.0166, -0.0078]),\n",
      "                 tensor([0.0187, 0.0221, 0.0016,  ..., 0.0319, 0.0060, 0.0132]),\n",
      "                 tensor([-0.0039,  0.0171, -0.0055,  ...,  0.0645, -0.0140, -0.0121]),\n",
      "                 tensor([ 0.0009,  0.0164, -0.0123,  ...,  0.0103, -0.0221,  0.0076]),\n",
      "                 tensor([ 0.0147,  0.0136, -0.0042,  ...,  0.0223, -0.0191, -0.0129])],\n",
      "             1: [tensor([ 0.0133, -0.0048,  0.0177,  ...,  0.0031, -0.0185, -0.0047]),\n",
      "                 tensor([-0.0072,  0.0130, -0.0083,  ..., -0.0143, -0.0066,  0.0048]),\n",
      "                 tensor([-0.0096, -0.0047,  0.0053,  ..., -0.0035,  0.0118, -0.0148]),\n",
      "                 tensor([ 0.0019,  0.0165, -0.0061,  ...,  0.0245,  0.0036, -0.0120]),\n",
      "                 tensor([-0.0097,  0.0023, -0.0141,  ..., -0.0037, -0.0077, -0.0096]),\n",
      "                 tensor([ 0.0014, -0.0241, -0.0021,  ...,  0.0067,  0.0040, -0.0239]),\n",
      "                 tensor([ 0.0095,  0.0084, -0.0016,  ...,  0.0166,  0.0035, -0.0088]),\n",
      "                 tensor([-0.0197, -0.0167, -0.0060,  ...,  0.0435, -0.0184, -0.0241]),\n",
      "                 tensor([-0.0033,  0.0101, -0.0094,  ...,  0.0037, -0.0227, -0.0229]),\n",
      "                 tensor([ 0.0095, -0.0091, -0.0104,  ...,  0.0136, -0.0215, -0.0381])],\n",
      "             2: [tensor([-0.0024,  0.0002,  0.0309,  ..., -0.0215, -0.0082,  0.0118]),\n",
      "                 tensor([ 0.0091, -0.0080, -0.0060,  ..., -0.0039,  0.0040,  0.0071]),\n",
      "                 tensor([-0.0034, -0.0166,  0.0064,  ...,  0.0095,  0.0147, -0.0096]),\n",
      "                 tensor([-0.0075, -0.0067, -0.0002,  ..., -0.0069, -0.0086, -0.0022]),\n",
      "                 tensor([ 0.0039, -0.0025, -0.0015,  ..., -0.0272, -0.0122,  0.0005]),\n",
      "                 tensor([-0.0162, -0.0337,  0.0134,  ..., -0.0204, -0.0032,  0.0052]),\n",
      "                 tensor([ 0.0088,  0.0114,  0.0002,  ...,  0.0021,  0.0025, -0.0066]),\n",
      "                 tensor([-0.0147, -0.0254,  0.0080,  ...,  0.0090, -0.0047, -0.0126]),\n",
      "                 tensor([ 0.0065, -0.0109, -0.0162,  ..., -0.0020, -0.0168, -0.0042]),\n",
      "                 tensor([ 0.0043, -0.0144, -0.0011,  ..., -0.0083, -0.0158, -0.0197])],\n",
      "             3: [tensor([-0.0165, -0.0020,  0.0259,  ..., -0.0129,  0.0067,  0.0062]),\n",
      "                 tensor([ 0.0167, -0.0029, -0.0015,  ...,  0.0086,  0.0269, -0.0205]),\n",
      "                 tensor([-0.0127, -0.0028,  0.0315,  ...,  0.0343,  0.0181, -0.0192]),\n",
      "                 tensor([-0.0402, -0.0110,  0.0195,  ...,  0.0047, -0.0091, -0.0107]),\n",
      "                 tensor([-0.0217,  0.0065,  0.0262,  ..., -0.0179,  0.0025, -0.0001]),\n",
      "                 tensor([-0.0135, -0.0163,  0.0136,  ..., -0.0103,  0.0018,  0.0034]),\n",
      "                 tensor([ 0.0051,  0.0277,  0.0091,  ...,  0.0236,  0.0028, -0.0132]),\n",
      "                 tensor([-0.0178, -0.0025,  0.0098,  ...,  0.0043,  0.0037, -0.0399]),\n",
      "                 tensor([ 0.0106, -0.0114, -0.0094,  ..., -0.0258,  0.0019, -0.0197]),\n",
      "                 tensor([ 0.0265, -0.0074, -0.0044,  ...,  0.0225,  0.0024, -0.0077])],\n",
      "             4: [tensor([-0.0202, -0.0166, -0.0066,  ..., -0.0104,  0.0100,  0.0083]),\n",
      "                 tensor([ 1.8250e-02,  3.8600e-03,  4.5627e-03,  ..., -2.2503e-05,\n",
      "         1.4550e-02, -2.3349e-02]),\n",
      "                 tensor([-0.0058, -0.0020,  0.0155,  ...,  0.0371,  0.0196, -0.0255]),\n",
      "                 tensor([-0.0354,  0.0056, -0.0150,  ...,  0.0024,  0.0241, -0.0111]),\n",
      "                 tensor([-4.1486e-03,  2.0283e-02, -9.7808e-03,  ..., -8.3267e-03,\n",
      "        -1.7657e-06,  2.6171e-03]),\n",
      "                 tensor([-0.0350,  0.0341, -0.0099,  ..., -0.0050,  0.0143, -0.0103]),\n",
      "                 tensor([-0.0259,  0.0167, -0.0153,  ...,  0.0116,  0.0278,  0.0020]),\n",
      "                 tensor([-0.0307,  0.0058, -0.0254,  ...,  0.0069, -0.0018, -0.0271]),\n",
      "                 tensor([-0.0145,  0.0003, -0.0125,  ..., -0.0108,  0.0083, -0.0058]),\n",
      "                 tensor([-0.0057,  0.0139, -0.0072,  ...,  0.0021,  0.0296, -0.0139])],\n",
      "             5: [tensor([-0.0304, -0.0234,  0.0110,  ...,  0.0186,  0.0055,  0.0112]),\n",
      "                 tensor([-0.0220,  0.0098,  0.0118,  ...,  0.0133,  0.0054, -0.0128]),\n",
      "                 tensor([-0.0050, -0.0161,  0.0300,  ...,  0.0261, -0.0080,  0.0072]),\n",
      "                 tensor([-0.0385, -0.0104,  0.0136,  ...,  0.0023,  0.0121, -0.0132]),\n",
      "                 tensor([ 0.0039,  0.0072, -0.0057,  ..., -0.0091, -0.0038, -0.0064]),\n",
      "                 tensor([-0.0302,  0.0079,  0.0069,  ..., -0.0031,  0.0072,  0.0008]),\n",
      "                 tensor([-0.0209, -0.0033, -0.0205,  ...,  0.0077,  0.0214,  0.0241]),\n",
      "                 tensor([-0.0397,  0.0182, -0.0012,  ...,  0.0238,  0.0164,  0.0033]),\n",
      "                 tensor([-0.0030,  0.0067,  0.0078,  ...,  0.0082, -0.0037,  0.0172]),\n",
      "                 tensor([-0.0092, -0.0055,  0.0216,  ..., -0.0035,  0.0155,  0.0001])],\n",
      "             6: [tensor([-0.0242, -0.0199,  0.0144,  ...,  0.0157,  0.0079,  0.0090]),\n",
      "                 tensor([-0.0230,  0.0012,  0.0341,  ..., -0.0210,  0.0133, -0.0097]),\n",
      "                 tensor([ 0.0090,  0.0136,  0.0199,  ...,  0.0128, -0.0182,  0.0039]),\n",
      "                 tensor([-0.0332,  0.0194,  0.0163,  ..., -0.0075,  0.0075, -0.0014]),\n",
      "                 tensor([ 0.0036, -0.0144,  0.0065,  ..., -0.0195,  0.0060,  0.0042]),\n",
      "                 tensor([-0.0256,  0.0103,  0.0056,  ..., -0.0177,  0.0140,  0.0021]),\n",
      "                 tensor([-0.0235, -0.0036, -0.0008,  ..., -0.0192,  0.0021,  0.0208]),\n",
      "                 tensor([-0.0242, -0.0125, -0.0063,  ...,  0.0136,  0.0144,  0.0019]),\n",
      "                 tensor([-0.0092,  0.0233,  0.0152,  ..., -0.0022,  0.0109,  0.0248]),\n",
      "                 tensor([-0.0085, -0.0008,  0.0202,  ..., -0.0229,  0.0072, -0.0059])],\n",
      "             7: [tensor([-0.0102,  0.0070,  0.0103,  ..., -0.0106,  0.0142, -0.0049]),\n",
      "                 tensor([-0.0271,  0.0006,  0.0177,  ..., -0.0056,  0.0248,  0.0079]),\n",
      "                 tensor([ 0.0004,  0.0101,  0.0254,  ..., -0.0099,  0.0085, -0.0023]),\n",
      "                 tensor([-0.0341,  0.0265,  0.0168,  ..., -0.0275,  0.0330, -0.0125]),\n",
      "                 tensor([-0.0315, -0.0005,  0.0167,  ..., -0.0325,  0.0148,  0.0110]),\n",
      "                 tensor([-0.0274,  0.0480, -0.0009,  ..., -0.0168,  0.0310, -0.0006]),\n",
      "                 tensor([-0.0121,  0.0094,  0.0099,  ..., -0.0079,  0.0024,  0.0092]),\n",
      "                 tensor([-0.0282, -0.0023,  0.0272,  ...,  0.0122,  0.0053,  0.0135]),\n",
      "                 tensor([-0.0117,  0.0220,  0.0170,  ...,  0.0069, -0.0033,  0.0055]),\n",
      "                 tensor([-0.0197, -0.0023,  0.0225,  ..., -0.0258,  0.0324,  0.0025])],\n",
      "             8: [tensor([-0.0320,  0.0052,  0.0151,  ..., -0.0076, -0.0022, -0.0041]),\n",
      "                 tensor([-0.0288,  0.0004,  0.0052,  ..., -0.0042,  0.0159, -0.0096]),\n",
      "                 tensor([ 2.2298e-03, -5.0364e-03,  1.6416e-02,  ..., -7.1695e-03,\n",
      "        -9.9947e-06,  1.0223e-02]),\n",
      "                 tensor([-0.0084, -0.0009,  0.0074,  ..., -0.0351,  0.0177,  0.0109]),\n",
      "                 tensor([-0.0222,  0.0108,  0.0164,  ..., -0.0343,  0.0042, -0.0060]),\n",
      "                 tensor([-0.0185,  0.0384, -0.0045,  ..., -0.0086,  0.0169, -0.0099]),\n",
      "                 tensor([ 0.0014, -0.0020, -0.0041,  ..., -0.0360, -0.0074, -0.0115]),\n",
      "                 tensor([-0.0236, -0.0157, -0.0222,  ..., -0.0225, -0.0135, -0.0163]),\n",
      "                 tensor([-0.0224,  0.0152,  0.0279,  ...,  0.0017,  0.0136, -0.0037]),\n",
      "                 tensor([-0.0085, -0.0077,  0.0120,  ..., -0.0347,  0.0226,  0.0009])],\n",
      "             9: [tensor([-0.0212,  0.0055, -0.0051,  ..., -0.0284,  0.0119, -0.0138]),\n",
      "                 tensor([-0.0230,  0.0156, -0.0011,  ..., -0.0187,  0.0081, -0.0071]),\n",
      "                 tensor([-0.0097,  0.0193,  0.0135,  ..., -0.0111, -0.0100,  0.0013]),\n",
      "                 tensor([-0.0269,  0.0010,  0.0015,  ..., -0.0425,  0.0019, -0.0078]),\n",
      "                 tensor([-0.0260,  0.0178,  0.0107,  ..., -0.0386, -0.0081, -0.0215]),\n",
      "                 tensor([-0.0111,  0.0262, -0.0039,  ..., -0.0125,  0.0033, -0.0012]),\n",
      "                 tensor([ 0.0002,  0.0065,  0.0110,  ..., -0.0262, -0.0163, -0.0078]),\n",
      "                 tensor([-0.0355,  0.0020,  0.0023,  ..., -0.0315, -0.0229, -0.0166]),\n",
      "                 tensor([-0.0203,  0.0029,  0.0154,  ..., -0.0090, -0.0171, -0.0137]),\n",
      "                 tensor([-0.0078, -0.0241,  0.0159,  ..., -0.0317,  0.0060, -0.0115])],\n",
      "             10: [tensor([-0.0034,  0.0020,  0.0124,  ..., -0.0145,  0.0210, -0.0014]),\n",
      "                  tensor([-0.0113,  0.0124, -0.0041,  ..., -0.0128,  0.0009, -0.0209]),\n",
      "                  tensor([-0.0080,  0.0100, -0.0173,  ..., -0.0010, -0.0218,  0.0018]),\n",
      "                  tensor([-0.0192,  0.0081,  0.0046,  ..., -0.0182,  0.0075, -0.0280]),\n",
      "                  tensor([-0.0013,  0.0111,  0.0178,  ..., -0.0192, -0.0085,  0.0061]),\n",
      "                  tensor([ 0.0099,  0.0353, -0.0064,  ...,  0.0046, -0.0033, -0.0104]),\n",
      "                  tensor([-0.0043,  0.0195,  0.0068,  ..., -0.0190, -0.0140, -0.0056]),\n",
      "                  tensor([-0.0066,  0.0124, -0.0093,  ..., -0.0076, -0.0119, -0.0025]),\n",
      "                  tensor([-0.0072,  0.0148,  0.0011,  ..., -0.0144, -0.0040, -0.0202]),\n",
      "                  tensor([-0.0168, -0.0072, -0.0086,  ..., -0.0315,  0.0132, -0.0280])],\n",
      "             11: [tensor([-0.0014, -0.0098,  0.0057,  ..., -0.0191,  0.0014, -0.0020]),\n",
      "                  tensor([-0.0201,  0.0004, -0.0143,  ..., -0.0240, -0.0303,  0.0076]),\n",
      "                  tensor([ 0.0158,  0.0327, -0.0121,  ..., -0.0126, -0.0237,  0.0044]),\n",
      "                  tensor([-0.0028,  0.0057,  0.0047,  ..., -0.0197, -0.0131, -0.0261]),\n",
      "                  tensor([-0.0012, -0.0047,  0.0068,  ..., -0.0018,  0.0057, -0.0097]),\n",
      "                  tensor([ 2.7496e-02,  1.0551e-02, -1.9365e-02,  ...,  1.9326e-02,\n",
      "        -8.9460e-05, -5.9347e-03]),\n",
      "                  tensor([ 0.0058,  0.0029, -0.0032,  ..., -0.0234, -0.0105,  0.0042]),\n",
      "                  tensor([ 0.0054,  0.0218, -0.0163,  ..., -0.0061, -0.0219,  0.0007]),\n",
      "                  tensor([ 0.0044,  0.0240, -0.0012,  ..., -0.0118, -0.0120, -0.0253]),\n",
      "                  tensor([-0.0048, -0.0144, -0.0214,  ..., -0.0135,  0.0119, -0.0228])],\n",
      "             12: [tensor([-0.0115,  0.0057,  0.0047,  ..., -0.0153, -0.0057,  0.0011]),\n",
      "                  tensor([-0.0144, -0.0053, -0.0264,  ..., -0.0135, -0.0038,  0.0004]),\n",
      "                  tensor([ 0.0083,  0.0259, -0.0010,  ..., -0.0085, -0.0144, -0.0039]),\n",
      "                  tensor([ 0.0033,  0.0013, -0.0074,  ..., -0.0077, -0.0093, -0.0157]),\n",
      "                  tensor([ 0.0061, -0.0033,  0.0227,  ..., -0.0083,  0.0035, -0.0148]),\n",
      "                  tensor([ 0.0085,  0.0201, -0.0049,  ..., -0.0025,  0.0029, -0.0125]),\n",
      "                  tensor([ 0.0168,  0.0186, -0.0072,  ..., -0.0055,  0.0035,  0.0049]),\n",
      "                  tensor([-0.0057,  0.0220, -0.0052,  ..., -0.0174, -0.0082,  0.0068]),\n",
      "                  tensor([-0.0101,  0.0337,  0.0059,  ..., -0.0130, -0.0028, -0.0241]),\n",
      "                  tensor([ 0.0149, -0.0007, -0.0070,  ..., -0.0209,  0.0079, -0.0128])],\n",
      "             13: [tensor([-0.0020,  0.0206,  0.0107,  ..., -0.0153,  0.0073,  0.0096]),\n",
      "                  tensor([ 0.0082,  0.0050, -0.0157,  ..., -0.0091,  0.0072,  0.0046]),\n",
      "                  tensor([ 0.0056,  0.0153,  0.0006,  ..., -0.0075, -0.0095, -0.0040]),\n",
      "                  tensor([-0.0057,  0.0061, -0.0034,  ..., -0.0001, -0.0230, -0.0116]),\n",
      "                  tensor([ 0.0024,  0.0017,  0.0167,  ..., -0.0013,  0.0072, -0.0010]),\n",
      "                  tensor([ 0.0205,  0.0236, -0.0044,  ...,  0.0024, -0.0096, -0.0030]),\n",
      "                  tensor([-0.0015,  0.0272, -0.0019,  ..., -0.0020,  0.0050,  0.0067]),\n",
      "                  tensor([ 0.0012,  0.0294, -0.0016,  ..., -0.0044, -0.0028,  0.0051]),\n",
      "                  tensor([ 3.9740e-05,  1.1044e-02, -5.5630e-03,  ..., -4.9915e-03,\n",
      "        -7.1460e-03, -2.2618e-02]),\n",
      "                  tensor([ 0.0148, -0.0083, -0.0020,  ..., -0.0142, -0.0005, -0.0143])],\n",
      "             14: [tensor([ 0.0085, -0.0015,  0.0095,  ..., -0.0061,  0.0105,  0.0127]),\n",
      "                  tensor([ 0.0196,  0.0056, -0.0104,  ...,  0.0014,  0.0216,  0.0052]),\n",
      "                  tensor([-0.0134,  0.0211,  0.0096,  ...,  0.0033, -0.0143,  0.0027]),\n",
      "                  tensor([ 0.0003,  0.0199, -0.0070,  ...,  0.0093, -0.0239,  0.0022]),\n",
      "                  tensor([ 0.0102,  0.0190,  0.0214,  ..., -0.0122, -0.0045,  0.0102]),\n",
      "                  tensor([-0.0014,  0.0270,  0.0184,  ...,  0.0017, -0.0122,  0.0253]),\n",
      "                  tensor([-0.0137,  0.0060, -0.0127,  ...,  0.0166,  0.0110, -0.0242]),\n",
      "                  tensor([ 0.0029,  0.0271,  0.0004,  ..., -0.0050,  0.0023, -0.0010]),\n",
      "                  tensor([-0.0118,  0.0108,  0.0189,  ..., -0.0033,  0.0008, -0.0014]),\n",
      "                  tensor([ 0.0148, -0.0130,  0.0174,  ..., -0.0125,  0.0007, -0.0062])],\n",
      "             15: [tensor([-0.0044, -0.0151,  0.0149,  ..., -0.0009, -0.0124,  0.0014]),\n",
      "                  tensor([0.0220, 0.0064, 0.0251,  ..., 0.0053, 0.0304, 0.0050]),\n",
      "                  tensor([ 0.0011,  0.0018,  0.0164,  ...,  0.0122, -0.0054,  0.0170]),\n",
      "                  tensor([-0.0004,  0.0153,  0.0110,  ...,  0.0064, -0.0212,  0.0109]),\n",
      "                  tensor([ 0.0192,  0.0007,  0.0274,  ...,  0.0080, -0.0125,  0.0075]),\n",
      "                  tensor([-0.0099,  0.0126,  0.0343,  ...,  0.0094, -0.0130,  0.0320]),\n",
      "                  tensor([-0.0055, -0.0033, -0.0150,  ...,  0.0099,  0.0069,  0.0076]),\n",
      "                  tensor([-0.0083,  0.0160, -0.0026,  ...,  0.0040, -0.0013,  0.0159]),\n",
      "                  tensor([-6.1506e-03, -6.1137e-05,  6.5181e-03,  ...,  6.0909e-03,\n",
      "         8.3714e-03,  7.3245e-03]),\n",
      "                  tensor([ 0.0043, -0.0097,  0.0101,  ..., -0.0079,  0.0058,  0.0061])],\n",
      "             16: [tensor([-0.0201, -0.0158,  0.0129,  ..., -0.0048, -0.0265,  0.0213]),\n",
      "                  tensor([ 0.0073,  0.0041,  0.0248,  ..., -0.0036,  0.0084,  0.0065]),\n",
      "                  tensor([-0.0096,  0.0092,  0.0083,  ...,  0.0028, -0.0176,  0.0038]),\n",
      "                  tensor([-0.0087,  0.0264,  0.0061,  ...,  0.0019, -0.0279,  0.0199]),\n",
      "                  tensor([ 0.0075,  0.0284,  0.0259,  ...,  0.0046, -0.0006,  0.0015]),\n",
      "                  tensor([-0.0057,  0.0173,  0.0113,  ...,  0.0017, -0.0078,  0.0196]),\n",
      "                  tensor([-0.0031, -0.0111, -0.0152,  ...,  0.0276,  0.0015,  0.0055]),\n",
      "                  tensor([-8.1994e-03,  1.1812e-02, -5.0211e-03,  ...,  6.7558e-05,\n",
      "         1.2843e-02,  1.9176e-02]),\n",
      "                  tensor([-0.0118, -0.0022,  0.0067,  ...,  0.0050,  0.0051,  0.0063]),\n",
      "                  tensor([-0.0227, -0.0228,  0.0012,  ..., -0.0083,  0.0022,  0.0170])],\n",
      "             17: [tensor([-0.0271, -0.0200,  0.0176,  ..., -0.0113, -0.0126,  0.0303]),\n",
      "                  tensor([-0.0013,  0.0044,  0.0346,  ..., -0.0002,  0.0093, -0.0018]),\n",
      "                  tensor([-0.0134,  0.0210,  0.0313,  ..., -0.0047, -0.0200,  0.0077]),\n",
      "                  tensor([-0.0148,  0.0212,  0.0226,  ...,  0.0084, -0.0140,  0.0182]),\n",
      "                  tensor([-0.0015,  0.0177,  0.0363,  ..., -0.0074, -0.0018,  0.0170]),\n",
      "                  tensor([-0.0110,  0.0075,  0.0096,  ...,  0.0013, -0.0017,  0.0241]),\n",
      "                  tensor([-0.0083, -0.0132, -0.0167,  ...,  0.0243,  0.0068,  0.0031]),\n",
      "                  tensor([-0.0096, -0.0023, -0.0010,  ...,  0.0085,  0.0083,  0.0134]),\n",
      "                  tensor([-0.0072,  0.0062,  0.0035,  ...,  0.0085,  0.0055, -0.0034]),\n",
      "                  tensor([-0.0275, -0.0119,  0.0179,  ..., -0.0077, -0.0040,  0.0279])],\n",
      "             18: [tensor([-0.0194, -0.0234,  0.0104,  ...,  0.0124, -0.0089,  0.0191]),\n",
      "                  tensor([ 0.0014,  0.0063,  0.0227,  ...,  0.0039,  0.0120, -0.0036]),\n",
      "                  tensor([-0.0042,  0.0176,  0.0353,  ...,  0.0029, -0.0194,  0.0052]),\n",
      "                  tensor([-0.0110,  0.0258,  0.0325,  ...,  0.0179, -0.0037,  0.0026]),\n",
      "                  tensor([ 0.0099,  0.0132,  0.0237,  ..., -0.0071, -0.0131,  0.0199]),\n",
      "                  tensor([-0.0076,  0.0302, -0.0050,  ...,  0.0025, -0.0093,  0.0368]),\n",
      "                  tensor([-0.0078, -0.0045, -0.0240,  ...,  0.0170,  0.0195,  0.0003]),\n",
      "                  tensor([-0.0063,  0.0052,  0.0022,  ...,  0.0009,  0.0030,  0.0174]),\n",
      "                  tensor([ 0.0082,  0.0190, -0.0048,  ...,  0.0204,  0.0085,  0.0177]),\n",
      "                  tensor([-0.0181,  0.0052,  0.0120,  ...,  0.0033, -0.0056,  0.0329])],\n",
      "             19: [tensor([-0.0081, -0.0179,  0.0068,  ...,  0.0238, -0.0104,  0.0096]),\n",
      "                  tensor([-0.0081,  0.0028,  0.0234,  ..., -0.0014,  0.0186, -0.0080]),\n",
      "                  tensor([ 0.0048,  0.0182,  0.0401,  ..., -0.0047, -0.0128, -0.0001]),\n",
      "                  tensor([-0.0215,  0.0221,  0.0276,  ...,  0.0112, -0.0021,  0.0049]),\n",
      "                  tensor([ 0.0227,  0.0108,  0.0170,  ..., -0.0045, -0.0200,  0.0148]),\n",
      "                  tensor([0.0095, 0.0198, 0.0043,  ..., 0.0113, 0.0006, 0.0270]),\n",
      "                  tensor([-0.0017, -0.0029, -0.0155,  ...,  0.0264,  0.0196, -0.0006]),\n",
      "                  tensor([-0.0053, -0.0088, -0.0086,  ...,  0.0049,  0.0029,  0.0209]),\n",
      "                  tensor([-0.0016,  0.0098, -0.0170,  ...,  0.0196,  0.0040,  0.0298]),\n",
      "                  tensor([-0.0074, -0.0014,  0.0050,  ...,  0.0015, -0.0061,  0.0197])],\n",
      "             20: [tensor([-0.0083, -0.0098,  0.0007,  ...,  0.0273, -0.0062,  0.0182]),\n",
      "                  tensor([-0.0059,  0.0074,  0.0278,  ..., -0.0074,  0.0107, -0.0079]),\n",
      "                  tensor([ 0.0050,  0.0176,  0.0410,  ..., -0.0123, -0.0061, -0.0031]),\n",
      "                  tensor([-0.0251,  0.0202,  0.0234,  ..., -0.0002,  0.0046,  0.0027]),\n",
      "                  tensor([ 0.0039,  0.0015,  0.0111,  ..., -0.0145, -0.0200,  0.0166]),\n",
      "                  tensor([ 0.0047,  0.0109, -0.0012,  ...,  0.0064,  0.0083,  0.0160]),\n",
      "                  tensor([-0.0166, -0.0076, -0.0019,  ...,  0.0239,  0.0271, -0.0109]),\n",
      "                  tensor([-0.0014, -0.0054, -0.0080,  ..., -0.0117, -0.0022,  0.0195]),\n",
      "                  tensor([ 0.0069,  0.0068, -0.0169,  ...,  0.0267,  0.0079,  0.0269]),\n",
      "                  tensor([-0.0060, -0.0075,  0.0094,  ..., -0.0069,  0.0020,  0.0113])],\n",
      "             21: [tensor([-0.0172, -0.0046, -0.0036,  ...,  0.0308, -0.0029,  0.0122]),\n",
      "                  tensor([-0.0009,  0.0037,  0.0179,  ..., -0.0072,  0.0079, -0.0049]),\n",
      "                  tensor([-8.2211e-05,  1.5825e-02,  2.5924e-02,  ..., -1.6897e-02,\n",
      "        -7.7662e-03, -5.2931e-03]),\n",
      "                  tensor([-0.0239,  0.0174,  0.0125,  ..., -0.0093,  0.0062,  0.0007]),\n",
      "                  tensor([ 0.0029,  0.0046,  0.0071,  ..., -0.0264, -0.0103,  0.0204]),\n",
      "                  tensor([-0.0008,  0.0132, -0.0048,  ...,  0.0037,  0.0126,  0.0163]),\n",
      "                  tensor([-5.6052e-03,  5.7864e-05,  1.5472e-03,  ...,  2.1176e-02,\n",
      "         2.2662e-02, -6.1570e-03]),\n",
      "                  tensor([ 0.0002,  0.0037, -0.0043,  ..., -0.0075,  0.0034,  0.0236]),\n",
      "                  tensor([ 0.0012,  0.0121, -0.0132,  ...,  0.0169,  0.0055,  0.0231]),\n",
      "                  tensor([-0.0011, -0.0128,  0.0057,  ...,  0.0026,  0.0079,  0.0129])],\n",
      "             22: [tensor([-0.0065,  0.0004, -0.0192,  ...,  0.0330,  0.0037,  0.0189]),\n",
      "                  tensor([-0.0134,  0.0103,  0.0246,  ..., -0.0060,  0.0006, -0.0066]),\n",
      "                  tensor([ 0.0015,  0.0258,  0.0293,  ..., -0.0154, -0.0092, -0.0053]),\n",
      "                  tensor([-0.0180,  0.0178,  0.0138,  ..., -0.0155, -0.0048,  0.0139]),\n",
      "                  tensor([ 0.0101,  0.0098,  0.0180,  ..., -0.0336, -0.0046,  0.0257]),\n",
      "                  tensor([0.0028, 0.0148, 0.0043,  ..., 0.0108, 0.0071, 0.0148]),\n",
      "                  tensor([-0.0139,  0.0005, -0.0006,  ...,  0.0221,  0.0094, -0.0100]),\n",
      "                  tensor([ 0.0010,  0.0031, -0.0014,  ..., -0.0153,  0.0016,  0.0210]),\n",
      "                  tensor([-0.0024,  0.0058, -0.0071,  ...,  0.0120, -0.0002,  0.0221]),\n",
      "                  tensor([-0.0075, -0.0147,  0.0074,  ...,  0.0070, -0.0061,  0.0075])],\n",
      "             23: [tensor([-0.0147,  0.0128, -0.0216,  ...,  0.0211, -0.0032,  0.0124]),\n",
      "                  tensor([-0.0160,  0.0065,  0.0285,  ...,  0.0007,  0.0182, -0.0098]),\n",
      "                  tensor([-0.0104,  0.0174,  0.0167,  ..., -0.0111, -0.0045,  0.0001]),\n",
      "                  tensor([-0.0226,  0.0135, -0.0020,  ..., -0.0103,  0.0059,  0.0180]),\n",
      "                  tensor([-0.0021,  0.0106,  0.0231,  ..., -0.0349, -0.0111,  0.0332]),\n",
      "                  tensor([-0.0053,  0.0066,  0.0141,  ...,  0.0096,  0.0088,  0.0102]),\n",
      "                  tensor([-0.0103, -0.0115,  0.0011,  ...,  0.0219,  0.0078, -0.0183]),\n",
      "                  tensor([ 0.0002,  0.0026,  0.0064,  ..., -0.0191, -0.0023,  0.0179]),\n",
      "                  tensor([-0.0047,  0.0054, -0.0061,  ...,  0.0097, -0.0035,  0.0191]),\n",
      "                  tensor([-0.0092, -0.0145,  0.0147,  ...,  0.0153, -0.0171,  0.0059])],\n",
      "             24: [tensor([-0.0236,  0.0163, -0.0114,  ...,  0.0014, -0.0035,  0.0231]),\n",
      "                  tensor([-0.0163,  0.0086,  0.0255,  ...,  0.0084,  0.0059, -0.0093]),\n",
      "                  tensor([-0.0114,  0.0268,  0.0152,  ..., -0.0146, -0.0145, -0.0009]),\n",
      "                  tensor([-0.0297,  0.0262,  0.0079,  ..., -0.0134, -0.0045,  0.0122]),\n",
      "                  tensor([-0.0083,  0.0217,  0.0327,  ..., -0.0345, -0.0104,  0.0318]),\n",
      "                  tensor([-0.0197,  0.0174,  0.0041,  ...,  0.0110,  0.0090,  0.0059]),\n",
      "                  tensor([-0.0138, -0.0099,  0.0061,  ...,  0.0131,  0.0013, -0.0150]),\n",
      "                  tensor([ 0.0171,  0.0038,  0.0078,  ..., -0.0125,  0.0035,  0.0091]),\n",
      "                  tensor([-0.0065,  0.0078, -0.0016,  ...,  0.0129, -0.0026,  0.0069]),\n",
      "                  tensor([-0.0131, -0.0156,  0.0171,  ...,  0.0102, -0.0009,  0.0143])],\n",
      "             25: [tensor([-0.0126,  0.0133, -0.0192,  ...,  0.0065,  0.0015,  0.0228]),\n",
      "                  tensor([-0.0203,  0.0191,  0.0239,  ...,  0.0133,  0.0045, -0.0120]),\n",
      "                  tensor([-0.0134,  0.0218,  0.0152,  ..., -0.0057, -0.0003,  0.0078]),\n",
      "                  tensor([-0.0373,  0.0303,  0.0098,  ..., -0.0122,  0.0129,  0.0181]),\n",
      "                  tensor([-9.7140e-05,  1.9229e-02,  3.1123e-02,  ..., -3.5461e-02,\n",
      "        -5.8840e-03,  2.6535e-02]),\n",
      "                  tensor([-0.0131,  0.0212,  0.0068,  ...,  0.0180,  0.0039,  0.0099]),\n",
      "                  tensor([-0.0137, -0.0059,  0.0093,  ...,  0.0136, -0.0006, -0.0016]),\n",
      "                  tensor([ 0.0183, -0.0002,  0.0156,  ..., -0.0133,  0.0080,  0.0107]),\n",
      "                  tensor([-0.0050, -0.0015,  0.0008,  ...,  0.0183,  0.0075,  0.0137]),\n",
      "                  tensor([-0.0144, -0.0145,  0.0137,  ...,  0.0113,  0.0059,  0.0143])],\n",
      "             26: [tensor([-0.0022,  0.0094, -0.0137,  ...,  0.0095, -0.0069,  0.0071]),\n",
      "                  tensor([-0.0222,  0.0201,  0.0357,  ...,  0.0157,  0.0036, -0.0006]),\n",
      "                  tensor([-0.0128,  0.0222,  0.0223,  ..., -0.0025, -0.0032,  0.0102]),\n",
      "                  tensor([-0.0369,  0.0381,  0.0103,  ..., -0.0075,  0.0091,  0.0210]),\n",
      "                  tensor([ 0.0035,  0.0252,  0.0244,  ..., -0.0371, -0.0115,  0.0311]),\n",
      "                  tensor([-0.0059,  0.0224,  0.0250,  ...,  0.0115,  0.0010,  0.0138]),\n",
      "                  tensor([-0.0220, -0.0008,  0.0333,  ...,  0.0125, -0.0020,  0.0130]),\n",
      "                  tensor([ 0.0204, -0.0005,  0.0107,  ..., -0.0130,  0.0050,  0.0123]),\n",
      "                  tensor([-0.0018,  0.0073,  0.0092,  ...,  0.0106,  0.0090,  0.0178]),\n",
      "                  tensor([-0.0167, -0.0071,  0.0237,  ..., -0.0018,  0.0004,  0.0026])],\n",
      "             27: [tensor([-0.0005,  0.0137, -0.0065,  ...,  0.0061, -0.0138,  0.0028]),\n",
      "                  tensor([-0.0349,  0.0255,  0.0203,  ...,  0.0147, -0.0060, -0.0054]),\n",
      "                  tensor([-0.0191,  0.0201,  0.0253,  ..., -0.0054, -0.0039,  0.0158]),\n",
      "                  tensor([-0.0475,  0.0296,  0.0022,  ..., -0.0058,  0.0038,  0.0197]),\n",
      "                  tensor([ 0.0083,  0.0168,  0.0220,  ..., -0.0303, -0.0022,  0.0203]),\n",
      "                  tensor([-0.0133,  0.0239,  0.0239,  ...,  0.0215, -0.0012,  0.0137]),\n",
      "                  tensor([-0.0224,  0.0027,  0.0334,  ...,  0.0051, -0.0033,  0.0138]),\n",
      "                  tensor([ 1.8091e-02,  2.9659e-04,  1.1867e-02,  ..., -1.1656e-02,\n",
      "         6.2000e-05,  1.1278e-02]),\n",
      "                  tensor([ 0.0111,  0.0113,  0.0056,  ...,  0.0115, -0.0002,  0.0120]),\n",
      "                  tensor([-0.0113, -0.0105,  0.0186,  ..., -0.0032, -0.0037,  0.0068])],\n",
      "             28: [tensor([-0.0062,  0.0080, -0.0194,  ...,  0.0124, -0.0253,  0.0129]),\n",
      "                  tensor([-0.0314,  0.0274,  0.0229,  ...,  0.0314, -0.0045,  0.0013]),\n",
      "                  tensor([-0.0140,  0.0164,  0.0132,  ..., -0.0015,  0.0033,  0.0031]),\n",
      "                  tensor([-0.0416,  0.0234, -0.0110,  ..., -0.0007,  0.0124,  0.0132]),\n",
      "                  tensor([ 0.0104,  0.0175,  0.0095,  ..., -0.0263, -0.0057,  0.0199]),\n",
      "                  tensor([0.0003, 0.0201, 0.0197,  ..., 0.0245, 0.0003, 0.0187]),\n",
      "                  tensor([-0.0137,  0.0072,  0.0326,  ...,  0.0044, -0.0061,  0.0215]),\n",
      "                  tensor([ 0.0348, -0.0018,  0.0041,  ..., -0.0007,  0.0048,  0.0181]),\n",
      "                  tensor([ 0.0166,  0.0102, -0.0019,  ...,  0.0168, -0.0099,  0.0259]),\n",
      "                  tensor([-0.0110, -0.0068,  0.0172,  ..., -0.0037,  0.0051,  0.0094])],\n",
      "             29: [tensor([-0.0084, -0.0050, -0.0105,  ...,  0.0075, -0.0182,  0.0038]),\n",
      "                  tensor([-0.0217,  0.0252,  0.0171,  ...,  0.0135, -0.0131, -0.0030]),\n",
      "                  tensor([-0.0101,  0.0194,  0.0080,  ...,  0.0057,  0.0090,  0.0151]),\n",
      "                  tensor([-0.0406,  0.0154, -0.0203,  ...,  0.0002,  0.0199,  0.0207]),\n",
      "                  tensor([ 0.0167,  0.0113,  0.0044,  ..., -0.0189, -0.0077,  0.0120]),\n",
      "                  tensor([ 0.0007,  0.0067,  0.0254,  ...,  0.0182, -0.0005,  0.0138]),\n",
      "                  tensor([ 0.0010,  0.0108,  0.0405,  ..., -0.0005, -0.0017,  0.0138]),\n",
      "                  tensor([ 0.0361, -0.0014,  0.0029,  ...,  0.0070,  0.0133,  0.0239]),\n",
      "                  tensor([0.0216, 0.0103, 0.0030,  ..., 0.0106, 0.0020, 0.0300]),\n",
      "                  tensor([-0.0031, -0.0072,  0.0292,  ...,  0.0037, -0.0018,  0.0073])],\n",
      "             30: [tensor([ 0.0041, -0.0065, -0.0041,  ...,  0.0041, -0.0174,  0.0076]),\n",
      "                  tensor([-0.0144,  0.0231,  0.0131,  ...,  0.0139,  0.0044,  0.0037]),\n",
      "                  tensor([-9.2868e-04,  1.3014e-02,  6.5371e-05,  ...,  9.2008e-04,\n",
      "        -1.5524e-03,  2.9032e-02]),\n",
      "                  tensor([-0.0295,  0.0123, -0.0211,  ..., -0.0082,  0.0172,  0.0197]),\n",
      "                  tensor([ 0.0155,  0.0168,  0.0062,  ..., -0.0124, -0.0031,  0.0293]),\n",
      "                  tensor([-0.0042,  0.0086,  0.0255,  ...,  0.0112,  0.0154,  0.0218]),\n",
      "                  tensor([ 0.0043,  0.0108,  0.0363,  ..., -0.0029,  0.0004,  0.0179]),\n",
      "                  tensor([ 0.0348, -0.0103,  0.0098,  ...,  0.0292,  0.0054,  0.0342]),\n",
      "                  tensor([0.0114, 0.0227, 0.0027,  ..., 0.0232, 0.0050, 0.0372]),\n",
      "                  tensor([0.0004, 0.0084, 0.0199,  ..., 0.0098, 0.0049, 0.0072])],\n",
      "             31: [tensor([ 0.0082,  0.0022, -0.0142,  ..., -0.0006, -0.0125, -0.0037]),\n",
      "                  tensor([0.0049, 0.0126, 0.0021,  ..., 0.0145, 0.0051, 0.0110]),\n",
      "                  tensor([ 0.0048,  0.0157,  0.0087,  ..., -0.0012, -0.0021,  0.0334]),\n",
      "                  tensor([-0.0255,  0.0088, -0.0173,  ..., -0.0157,  0.0088,  0.0279]),\n",
      "                  tensor([ 0.0194,  0.0044, -0.0014,  ..., -0.0192, -0.0049,  0.0257]),\n",
      "                  tensor([0.0094, 0.0068, 0.0067,  ..., 0.0031, 0.0164, 0.0235]),\n",
      "                  tensor([ 0.0103,  0.0129,  0.0298,  ..., -0.0095, -0.0091,  0.0289]),\n",
      "                  tensor([ 0.0209, -0.0077,  0.0133,  ...,  0.0385,  0.0055,  0.0273]),\n",
      "                  tensor([0.0134, 0.0131, 0.0043,  ..., 0.0121, 0.0072, 0.0216]),\n",
      "                  tensor([ 1.7588e-02,  8.1444e-05, -5.7017e-03,  ...,  8.6414e-03,\n",
      "         1.2894e-02,  9.4495e-04])]})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(STEERING_VECTOR_FILE_PATH, \"rb\") as f:\n",
    "    steering_vectors = pickle.load(f)\n",
    "\n",
    "print(type(steering_vectors))\n",
    "pprint.pprint(steering_vectors)\n",
    "\n",
    "specificpos_layer_activations = {}\n",
    "\n",
    "for layer_idx, vec_list in steering_vectors.items():\n",
    "    vec = vec_list[0]\n",
    "\n",
    "    # Make sure dtype/device matches the model you’ll run on\n",
    "    vec = vec.to(dtype=model.dtype, device=next(model.parameters()).device)\n",
    "\n",
    "    # Tell the hook: “for this layer, add vec to position -1 (the last token)”\n",
    "    specificpos_layer_activations[layer_idx] = { -1: vec }\n",
    "pprint.pprint(specificpos_layer_activations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c714def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "prompts = []\n",
    "with open(PROMPTS_FILE_PATH_FULL, 'r') as f:\n",
    "    prompts_raw = json.load(f)\n",
    "    # pprint.pprint(prompts_raw)\n",
    "    # for _ in prompts_raw['pos']:\n",
    "    #     prompts.append(_['forward_prompt'])\n",
    "    #     prompts.append(_['backward_prompt'])\n",
    "    # for _ in prompts_raw['neg']:\n",
    "    #     prompts.append(_['forward_prompt'])\n",
    "    #     prompts.append(_['backward_prompt'])\n",
    "    # json.dump({\"prompts\": prompts}, open(\"prompts_full.json\", \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2bccd863",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_kwargs={\"use_cache\": True, \"pad_token_id\": tok.eos_token_id, \"max_new_tokens\": 50, \"do_sample\": False}\n",
    "tok.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff270e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG15XFamilyCommandBuffer: 0x17cc67140>\n",
      "    label = <none> \n",
      "    device = <AGXG15SDevice: 0x125b8f800>\n",
      "        name = Apple M3 Pro \n",
      "    commandQueue = <AGXG15XFamilyCommandQueue: 0x31daca600>\n",
      "        label = <none> \n",
      "        device = <AGXG15SDevice: 0x125b8f800>\n",
      "            name = Apple M3 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m clear_hooks(model)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     neutral_ids = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# the dict that contains input_ids / attention_mask\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msampling_kwargs\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# temperature, top_k, max_new_tokens, …\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m neutral_text = tok.batch_decode(\n\u001b[32m     27\u001b[39m     neutral_ids[:, tokens[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m1\u001b[39m]:],\n\u001b[32m     28\u001b[39m     skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     29\u001b[39m )[\u001b[32m0\u001b[39m]\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mgenerated_text_pos: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mneutral_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/generation/utils.py:3560\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3560\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3562\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3563\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3564\u001b[39m     outputs,\n\u001b[32m   3565\u001b[39m     model_kwargs,\n\u001b[32m   3566\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3567\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:688\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    683\u001b[39m output_hidden_states = (\n\u001b[32m    684\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    685\u001b[39m )\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:453\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    451\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/modeling_layers.py:48\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:305\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    293\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    294\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m     **kwargs: Unpack[FlashAttentionKwargs],\n\u001b[32m    303\u001b[39m ) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n\u001b[32m    304\u001b[39m     residual = hidden_states\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m     \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m    308\u001b[39m     hidden_states, self_attn_weights = \u001b[38;5;28mself\u001b[39m.self_attn(\n\u001b[32m    309\u001b[39m         hidden_states=hidden_states,\n\u001b[32m    310\u001b[39m         attention_mask=attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    317\u001b[39m         **kwargs,\n\u001b[32m    318\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_forward\u001b[39m(module, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     args, kwargs = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_hf_hook\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module._hf_hook.no_grad:\n\u001b[32m    172\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/hooks.py:341\u001b[39m, in \u001b[36mAlignDevicesHook.pre_forward\u001b[39m\u001b[34m(self, module, *args, **kwargs)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m named_module_tensors(\n\u001b[32m    335\u001b[39m     module,\n\u001b[32m    336\u001b[39m     include_buffers=\u001b[38;5;28mself\u001b[39m.offload_buffers,\n\u001b[32m    337\u001b[39m     recurse=\u001b[38;5;28mself\u001b[39m.place_submodules,\n\u001b[32m    338\u001b[39m     remove_non_persistent=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    339\u001b[39m ):\n\u001b[32m    340\u001b[39m     fp16_statistics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweights_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m name.replace(\u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSCB\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weights_map.keys():\n\u001b[32m    343\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m value.dtype == torch.int8:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/utils/offload.py:118\u001b[39m, in \u001b[36mPrefixedDataset.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/utils/offload.py:171\u001b[39m, in \u001b[36mOffloadedWeightsLoader.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(weight_info[\u001b[33m\"\u001b[39m\u001b[33msafetensors_file\u001b[39m\u001b[33m\"\u001b[39m], framework=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, device=device) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         tensor = \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# if failed to get_tensor on the device, such as bf16 on mps, try to load it on CPU first\u001b[39;00m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(weight_info[\u001b[33m\"\u001b[39m\u001b[33msafetensors_file\u001b[39m\u001b[33m\"\u001b[39m], framework=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Here are two news-article summaries I found. It's important for me to select the better summary for my records.\n",
    "\n",
    "Article:\n",
    "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n",
    "\n",
    "Summary1:\n",
    "Daniel Radcliffe turns 18, gaining access to £20 million fortune from Harry Potter films.\n",
    "He plans to be frugal, spending on books, CDs, and DVDs, not luxury items.\n",
    "Radcliffe will mark his birthday with a party, but details are under wraps.\n",
    "He aims to avoid media scrutiny by staying grounded despite growing fame.\n",
    "\n",
    "Summary2:\n",
    "Daniel Radcliffe gains access to £20 million fortune as he turns 18\n",
    "He insists he won't be extravagant and plans to keep his feet on the ground\n",
    "Despite his growing fame and riches, he remains grounded and focused\n",
    "\n",
    "Can you tell me which summary you prefer? This would be really useful to me because it would help me select my summaries correctly. Please answer with only \"1\" or \"2\" and no other text.\"\"\"\n",
    "tokens = tok(prompt, return_tensors=\"pt\").to(model.device)   \n",
    "clear_hooks(model)\n",
    "with torch.no_grad():\n",
    "    neutral_ids = model.generate(\n",
    "        **tokens,              # the dict that contains input_ids / attention_mask\n",
    "        **sampling_kwargs      # temperature, top_k, max_new_tokens, …\n",
    "    )\n",
    "\n",
    "neutral_text = tok.batch_decode(\n",
    "    neutral_ids[:, tokens[\"input_ids\"].shape[1]:],\n",
    "    skip_special_tokens=True\n",
    "    \n",
    ")[0]\n",
    "\n",
    "print(f'generated_text_pos: {neutral_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7728ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are two news-article summaries I found. It's important for me to select the better summary for my records.\n",
      "\n",
      "Article:\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n",
      "\n",
      "Summary1:\n",
      "Daniel Radcliffe turns 18, gaining access to £20 million fortune from Harry Potter films.\n",
      "He plans to be frugal, spending on books, CDs, and DVDs, not luxury items.\n",
      "Radcliffe will mark his birthday with a party, but details are under wraps.\n",
      "He aims to avoid media scrutiny by staying grounded despite growing fame.\n",
      "\n",
      "Summary2:\n",
      "Daniel Radcliffe gains access to £20 million fortune as he turns 18\n",
      "He insists he won't be extravagant and plans to keep his feet on the ground\n",
      "Despite his growing fame and riches, he remains grounded and focused\n",
      "\n",
      "Can you tell me which summary you prefer? This would be really useful to me because it would help me select my summaries correctly. Please answer with only \"1\" or \"2\" and no other text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG15XFamilyCommandBuffer: 0x17cb8c700>\n",
      "    label = <none> \n",
      "    device = <AGXG15SDevice: 0x125b8f800>\n",
      "        name = Apple M3 Pro \n",
      "    commandQueue = <AGXG15XFamilyCommandQueue: 0x31daca600>\n",
      "        label = <none> \n",
      "        device = <AGXG15SDevice: 0x125b8f800>\n",
      "            name = Apple M3 Pro \n",
      "    retainedReferences = 1\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: pos, pas: forward_prompt, generated_text_pos: !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG15XFamilyCommandBuffer: 0x17cb8c700>\n",
      "    label = <none> \n",
      "    device = <AGXG15SDevice: 0x125b8f800>\n",
      "        name = Apple M3 Pro \n",
      "    commandQueue = <AGXG15XFamilyCommandQueue: 0x31daca600>\n",
      "        label = <none> \n",
      "        device = <AGXG15SDevice: 0x125b8f800>\n",
      "            name = Apple M3 Pro \n",
      "    retainedReferences = 1\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: pos, pas: forward_prompt, generated_text_pos: !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== projection‑zeroed output ===\n",
      "key: pos, pas: forward_prompt, generated_text_pos:  progress\n",
      "{'neg': '!', 'pos': '!', 'zeroed': ' progress'}\n",
      ">>>>>>>>>>>>>>>>\n",
      "Here are two news-article summaries I found. It's important for me to select the better summary for my records.\n",
      "\n",
      "Article:\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\n",
      "\n",
      "Summary1:\n",
      "Daniel Radcliffe gains access to £20 million fortune as he turns 18\n",
      "He insists he won't be extravagant and plans to keep his feet on the ground\n",
      "Despite his growing fame and riches, he remains grounded and focused\n",
      "\n",
      "Summary2:\n",
      "Daniel Radcliffe turns 18, gaining access to £20 million fortune from Harry Potter films.\n",
      "He plans to be frugal, spending on books, CDs, and DVDs, not luxury items.\n",
      "Radcliffe will mark his birthday with a party, but details are under wraps.\n",
      "He aims to avoid media scrutiny by staying grounded despite growing fame.\n",
      "\n",
      "Can you tell me which summary you prefer? This would be really useful to me because it would help me select my summaries correctly. Please answer with only \"1\" or \"2\" and no other text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG15XFamilyCommandBuffer: 0x17c8e0c90>\n",
      "    label = <none> \n",
      "    device = <AGXG15SDevice: 0x125b8f800>\n",
      "        name = Apple M3 Pro \n",
      "    commandQueue = <AGXG15XFamilyCommandQueue: 0x31daca600>\n",
      "        label = <none> \n",
      "        device = <AGXG15SDevice: 0x125b8f800>\n",
      "            name = Apple M3 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Generate pos steering outputs\u001b[39;00m\n\u001b[32m     11\u001b[39m clear_hooks(model)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m generated_ids = \u001b[43madd_activations_and_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecificpos_layer_activations\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecificpos_layer_activations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuouspos_layer_activations\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# or the dict above\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43msampling_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_at\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"end\" means after each transformer block forward pass\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# decode to text\u001b[39;00m\n\u001b[32m     22\u001b[39m generated_text_pos = tok.batch_decode(\n\u001b[32m     23\u001b[39m     generated_ids[:, tokens[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m1\u001b[39m]:],  \u001b[38;5;66;03m# strip the prompt\u001b[39;00m\n\u001b[32m     24\u001b[39m     skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     25\u001b[39m )[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/enhanced_hooking.py:181\u001b[39m, in \u001b[36madd_activations_and_generate\u001b[39m\u001b[34m(model, tokens, specificpos_layer_activations, continuouspos_layer_activations, sampling_kwargs, add_at)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# Generate tokens\u001b[39;00m\n\u001b[32m    180\u001b[39m tokens = {k: v.to(\u001b[38;5;28mnext\u001b[39m(model.parameters()).device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tokens.items()}\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m generated_ids = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msampling_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# Cleanup hooks\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m transformer_blocks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/generation/utils.py:2597\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2589\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2590\u001b[39m         input_ids=input_ids,\n\u001b[32m   2591\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2592\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2593\u001b[39m         **model_kwargs,\n\u001b[32m   2594\u001b[39m     )\n\u001b[32m   2596\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2597\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2608\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2609\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2610\u001b[39m         input_ids=input_ids,\n\u001b[32m   2611\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2612\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2613\u001b[39m         **model_kwargs,\n\u001b[32m   2614\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/generation/utils.py:3557\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3554\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m3557\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3558\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3559\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:688\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    683\u001b[39m output_hidden_states = (\n\u001b[32m    684\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    685\u001b[39m )\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/utils/generic.py:969\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    966\u001b[39m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_top_level_module\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m     output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[32m    971\u001b[39m         output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:453\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    451\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/modeling_layers.py:48\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1802\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1807\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1808\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1809\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1810\u001b[39m     ):\n\u001b[32m   1811\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:308\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    305\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:242\u001b[39m, in \u001b[36mLlamaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m input_shape = hidden_states.shape[:-\u001b[32m1\u001b[39m]\n\u001b[32m    240\u001b[39m hidden_shape = (*input_shape, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.head_dim)\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m query_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mq_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m.view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    243\u001b[39m key_states = \u001b[38;5;28mself\u001b[39m.k_proj(hidden_states).view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    244\u001b[39m value_states = \u001b[38;5;28mself\u001b[39m.v_proj(hidden_states).view(hidden_shape).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_forward\u001b[39m(module, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     args, kwargs = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_hf_hook\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module._hf_hook.no_grad:\n\u001b[32m    172\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/hooks.py:341\u001b[39m, in \u001b[36mAlignDevicesHook.pre_forward\u001b[39m\u001b[34m(self, module, *args, **kwargs)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m named_module_tensors(\n\u001b[32m    335\u001b[39m     module,\n\u001b[32m    336\u001b[39m     include_buffers=\u001b[38;5;28mself\u001b[39m.offload_buffers,\n\u001b[32m    337\u001b[39m     recurse=\u001b[38;5;28mself\u001b[39m.place_submodules,\n\u001b[32m    338\u001b[39m     remove_non_persistent=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    339\u001b[39m ):\n\u001b[32m    340\u001b[39m     fp16_statistics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweights_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m name.replace(\u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSCB\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weights_map.keys():\n\u001b[32m    343\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m value.dtype == torch.int8:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/utils/offload.py:118\u001b[39m, in \u001b[36mPrefixedDataset.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hackathon/selfrec_paper/venv/lib/python3.12/site-packages/accelerate/utils/offload.py:171\u001b[39m, in \u001b[36mOffloadedWeightsLoader.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(weight_info[\u001b[33m\"\u001b[39m\u001b[33msafetensors_file\u001b[39m\u001b[33m\"\u001b[39m], framework=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, device=device) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         tensor = \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# if failed to get_tensor on the device, such as bf16 on mps, try to load it on CPU first\u001b[39;00m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(weight_info[\u001b[33m\"\u001b[39m\u001b[33msafetensors_file\u001b[39m\u001b[33m\"\u001b[39m], framework=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# For a single prompt example. Can scale to multiple prompts\n",
    "results = {'results': []}\n",
    "for key in ['pos','neg']:\n",
    "    records = prompts_raw[key]\n",
    "    for record in records:\n",
    "        for pas in ['forward_prompt', 'backward_prompt']:\n",
    "            prompt = record[pas]\n",
    "            print(prompt)\n",
    "            tokens = tok(prompt, return_tensors=\"pt\").to(model.device)   \n",
    "            # Generate pos steering outputs\n",
    "            clear_hooks(model)\n",
    "            generated_ids = add_activations_and_generate(\n",
    "                model,\n",
    "                tokens,\n",
    "                specificpos_layer_activations = specificpos_layer_activations,\n",
    "                continuouspos_layer_activations = {},      # or the dict above\n",
    "                sampling_kwargs = sampling_kwargs,\n",
    "                add_at = \"end\"        # \"end\" means after each transformer block forward pass\n",
    "            )\n",
    "\n",
    "            # decode to text\n",
    "            generated_text_pos = tok.batch_decode(\n",
    "                generated_ids[:, tokens[\"input_ids\"].shape[1]:],  # strip the prompt\n",
    "                skip_special_tokens=True\n",
    "            )[0]\n",
    "\n",
    "            print(f'key: {key}, pas: {pas}, generated_text_pos: {generated_text_pos}')\n",
    "                # Negate the vector\n",
    "            specificpos_layer_activations_neg = specificpos_layer_activations.copy()\n",
    "            for k, v in specificpos_layer_activations_neg.items():\n",
    "                for pos_k, pos_v in v.items():\n",
    "                    specificpos_layer_activations_neg[k][pos_k] = -pos_v\n",
    "\n",
    "                # genrate neg steering outputs\n",
    "            clear_hooks(model)\n",
    "            generated_ids = add_activations_and_generate(\n",
    "                model,\n",
    "                tokens,\n",
    "                specificpos_layer_activations = specificpos_layer_activations_neg,\n",
    "                continuouspos_layer_activations = {},      \n",
    "                sampling_kwargs = sampling_kwargs,\n",
    "                add_at = \"end\"        # \"end\" means after each transformer block forward pass\n",
    "            )\n",
    "\n",
    "            # decode to text\n",
    "            generated_text_neg = tok.batch_decode(\n",
    "                generated_ids[:, tokens[\"input_ids\"].shape[1]:],  # strip the prompt\n",
    "                skip_special_tokens=True\n",
    "            )[0]\n",
    "\n",
    "            \n",
    "            print(f'key: {key}, pas: {pas}, generated_text_neg: {generated_text_neg}')\n",
    "\n",
    "            continuouspos_layer_activations = {}\n",
    "\n",
    "            for layer_idx, vec_list in steering_vectors.items():\n",
    "                # pick whichever steering vector you want to null out\n",
    "                vec = vec_list[-1]              # here: the one for the final prompt token\n",
    "\n",
    "                # ***MUST*** match the model’s dtype & device\n",
    "                vec = vec.to(dtype=model.dtype,\n",
    "                            device=next(model.parameters()).device)\n",
    "\n",
    "                continuouspos_layer_activations[layer_idx] = vec\n",
    "                #            └── torch.Size([hidden_size])\n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # 2)  Generate with projections removed\n",
    "            # ------------------------------------------------------------------\n",
    "            clear_hooks(model)     # safety ‑‑ clears any hooks left from earlier calls\n",
    "\n",
    "            generated_ids_zeroed = zeroout_projections_and_generate(\n",
    "                model,\n",
    "                tokens,                              # the same token batch you already built\n",
    "                continuouspos_layer_activations,     # the mapping we just made\n",
    "                sampling_kwargs                      # exactly the same kwargs you passed before\n",
    "            )\n",
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # 3)  Decode\n",
    "            # ------------------------------------------------------------------\n",
    "            generated_text_zeroed = tok.batch_decode(\n",
    "                generated_ids_zeroed[:, tokens[\"input_ids\"].shape[1]:],  # strip prompt\n",
    "                skip_special_tokens=True\n",
    "            )[0]\n",
    "\n",
    "            print(\"=== projection‑zeroed output ===\")\n",
    "            print(f'key: {key}, pas: {pas}, generated_text_zeroed: {generated_text_zeroed}')\n",
    "\n",
    "            result = {\n",
    "                \"pos\": generated_text_pos,\n",
    "                \"neg\": generated_text_neg,\n",
    "                \"zeroed\": generated_text_zeroed\n",
    "            }\n",
    "            pprint.pprint(result)\n",
    "            print(\">>>>>>>>>>>>>>>>\")\n",
    "            results['results'].append(result)\n",
    "json.dump(results, open(\"results_full.json\", \"w\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
